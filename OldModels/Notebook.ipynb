{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13019d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import keras.models\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad489fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_name):\n",
    "    audio_data, sample_rate = sf.read(file_name)\n",
    "    return audio_data[::8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fda4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    wav = load_audio(file_path)\n",
    "    wav = wav[:80000]\n",
    "    zero_padding = tf.zeros([80000] - tf.shape(wav), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, wav], 0)\n",
    "\n",
    "    spectrogram = tfio.audio.spectrogram(\n",
    "        wav, nfft=512, window=512, stride=512)\n",
    "\n",
    "    mel_spectrogram = tfio.audio.melscale(\n",
    "        spectrogram, rate=8000, mels=64, fmin=0, fmax=4000)\n",
    "\n",
    "    dbscale_mel_spectrogram = tfio.audio.dbscale(\n",
    "        mel_spectrogram, top_db=80)\n",
    "\n",
    "    freq_mask = tfio.audio.freq_mask(dbscale_mel_spectrogram, param=5)\n",
    "\n",
    "    time_mask = tfio.audio.time_mask(freq_mask, param=5)\n",
    "    time_mask = tf.expand_dims(time_mask, axis=2)\n",
    "    return time_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4a2ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_labels):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(157, 64, 1), kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(num_labels, activation='softmax'))\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2bb68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_test, y_test, num_labels, batch_amt, epoch_amt, save):\n",
    "    model = create_model(num_labels)\n",
    "\n",
    "    hist = model.fit(X_train, y_train, batch_size=batch_amt, epochs=epoch_amt, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "    if save:\n",
    "        model.save(\"model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bcd6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_file(file_name, model, label_encoder):\n",
    "    input = preprocess(\"./Data/Audio/acafly/XC136290.ogg\")\n",
    "    predicted_label = model.predict(input.numpy().reshape(1, 157, 64, 1))\n",
    "    classes_x = np.argmax(predicted_label, axis=1)\n",
    "    prediction_class = labelencoder.inverse_transform(classes_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b9cdf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b8e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"./Data/Audio/\"\n",
    "metadata = pd.read_csv('./Data/train_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd7dcfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = []\n",
    "for index_num, row in metadata.iterrows():\n",
    "    if row[\"primary_label\"] == \"banswa\":\n",
    "        break\n",
    "    file_name = os.path.join(audio_path + row[\"primary_label\"] + \"/\" + row[\"filename\"])\n",
    "    final_class_labels = row[\"primary_label\"]\n",
    "    data = preprocess(file_name)\n",
    "    extracted_features.append([data, final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3832e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features_df = pd.DataFrame(extracted_features, columns=['feature', 'class'])\n",
    "extracted_features_df = shuffle(extracted_features_df)\n",
    "extracted_features_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1245ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(extracted_features_df['feature'].tolist())\n",
    "y = np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "809cde49",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y = to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c991be94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 155, 62, 16)       160       \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 153, 60, 32)       4640      \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 151, 58, 64)       18496     \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 149, 56, 128)      73856     \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 147, 54, 128)      147584    \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 145, 52, 128)      147584    \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 143, 50, 128)      147584    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 915200)            0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 915200)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 512)               468582912 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 469,191,060\n",
      "Trainable params: 469,191,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "172/172 [==============================] - 423s 2s/step - loss: 13.5070 - accuracy: 0.1305 - val_loss: 7.5340 - val_accuracy: 0.1691\n",
      "Epoch 2/25\n",
      "172/172 [==============================] - 422s 2s/step - loss: 6.6090 - accuracy: 0.1724 - val_loss: 5.9779 - val_accuracy: 0.1953\n",
      "Epoch 3/25\n",
      "172/172 [==============================] - 423s 2s/step - loss: 5.5940 - accuracy: 0.1840 - val_loss: 5.4096 - val_accuracy: 0.1910\n",
      "Epoch 4/25\n",
      "172/172 [==============================] - 422s 2s/step - loss: 5.0744 - accuracy: 0.1913 - val_loss: 4.9120 - val_accuracy: 0.2026\n",
      "Epoch 5/25\n",
      "172/172 [==============================] - 423s 2s/step - loss: 4.6989 - accuracy: 0.2048 - val_loss: 4.6387 - val_accuracy: 0.1822\n",
      "Epoch 6/25\n",
      "172/172 [==============================] - 424s 2s/step - loss: 4.4403 - accuracy: 0.2223 - val_loss: 4.3505 - val_accuracy: 0.2318\n",
      "Epoch 7/25\n",
      "172/172 [==============================] - 421s 2s/step - loss: 4.2256 - accuracy: 0.2518 - val_loss: 4.2411 - val_accuracy: 0.2085\n",
      "Epoch 8/25\n",
      "172/172 [==============================] - 421s 2s/step - loss: 4.1193 - accuracy: 0.2802 - val_loss: 4.2709 - val_accuracy: 0.2143\n",
      "Epoch 9/25\n",
      "172/172 [==============================] - 422s 2s/step - loss: 4.0163 - accuracy: 0.3284 - val_loss: 4.4269 - val_accuracy: 0.2157\n",
      "Epoch 10/25\n",
      "172/172 [==============================] - 422s 2s/step - loss: 3.8922 - accuracy: 0.4016 - val_loss: 4.7960 - val_accuracy: 0.2201\n",
      "Epoch 11/25\n",
      "172/172 [==============================] - 422s 2s/step - loss: 3.8405 - accuracy: 0.5077 - val_loss: 5.8380 - val_accuracy: 0.2026\n",
      "Epoch 12/25\n",
      "172/172 [==============================] - 421s 2s/step - loss: 3.6154 - accuracy: 0.6443 - val_loss: 6.6597 - val_accuracy: 0.1706\n",
      "Epoch 13/25\n",
      "172/172 [==============================] - 421s 2s/step - loss: 3.3601 - accuracy: 0.7507 - val_loss: 7.7916 - val_accuracy: 0.1618\n",
      "Epoch 14/25\n",
      "172/172 [==============================] - 422s 2s/step - loss: 3.1018 - accuracy: 0.8298 - val_loss: 8.2086 - val_accuracy: 0.1735\n",
      "Epoch 15/25\n",
      "172/172 [==============================] - 422s 2s/step - loss: 3.3524 - accuracy: 0.8550 - val_loss: 7.2109 - val_accuracy: 0.1778\n",
      "Epoch 16/25\n",
      "172/172 [==============================] - 421s 2s/step - loss: 3.0447 - accuracy: 0.8896 - val_loss: 8.9061 - val_accuracy: 0.1720\n",
      "Epoch 17/25\n",
      "172/172 [==============================] - 421s 2s/step - loss: 2.8077 - accuracy: 0.9082 - val_loss: 8.2557 - val_accuracy: 0.1691\n",
      "Epoch 18/25\n",
      "172/172 [==============================] - 421s 2s/step - loss: 2.6060 - accuracy: 0.9355 - val_loss: 8.7926 - val_accuracy: 0.1589\n",
      "Epoch 19/25\n",
      "172/172 [==============================] - 421s 2s/step - loss: 2.5565 - accuracy: 0.9399 - val_loss: 9.2569 - val_accuracy: 0.1822\n",
      "Epoch 20/25\n",
      "172/172 [==============================] - 422s 2s/step - loss: 2.4339 - accuracy: 0.9391 - val_loss: 8.4196 - val_accuracy: 0.1676\n",
      "Epoch 21/25\n",
      "172/172 [==============================] - 422s 2s/step - loss: 2.2866 - accuracy: 0.9468 - val_loss: 10.3603 - val_accuracy: 0.1706\n",
      "Epoch 22/25\n",
      "172/172 [==============================] - 421s 2s/step - loss: 2.1876 - accuracy: 0.9501 - val_loss: 8.2624 - val_accuracy: 0.1531\n",
      "Epoch 23/25\n",
      "172/172 [==============================] - 422s 2s/step - loss: 2.2428 - accuracy: 0.9457 - val_loss: 7.4912 - val_accuracy: 0.1560\n",
      "Epoch 24/25\n",
      "172/172 [==============================] - 421s 2s/step - loss: 2.1575 - accuracy: 0.9544 - val_loss: 7.5882 - val_accuracy: 0.1647\n",
      "Epoch 25/25\n",
      "172/172 [==============================] - 422s 2s/step - loss: 2.0507 - accuracy: 0.9574 - val_loss: 8.0210 - val_accuracy: 0.1589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2038ad589d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = y.shape[1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "train_model(X_train, y_train, X_test, y_test, num_labels, 16, 25, True)\n",
    "\n",
    "#model = keras.models.load_model(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e320bbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
