{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13019d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "import keras.models\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D, Flatten, Dense, Lambda, Dropout, GaussianNoise\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad489fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_name):\n",
    "    audio_data, sample_rate = sf.read(file_name.numpy())\n",
    "    return audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fda4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    [wav,] = tf.py_function(load_audio, [file_path], [tf.float32])\n",
    "    wav = wav[:960000]\n",
    "    zero_padding = tf.zeros([960000] - tf.shape(wav), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, wav], 0)\n",
    "\n",
    "    spectrogram = tfio.audio.spectrogram(\n",
    "        wav, nfft=1024, window=1024, stride=int(960000/224) + 1)\n",
    "\n",
    "    mel_spectrogram = tfio.audio.melscale(\n",
    "        spectrogram, rate=32000, mels=224, fmin=0, fmax=16000)\n",
    "\n",
    "    dbscale_mel_spectrogram = tfio.audio.dbscale(\n",
    "        mel_spectrogram, top_db=80)\n",
    "\n",
    "    freq_mask = tfio.audio.freq_mask(dbscale_mel_spectrogram, param=10)\n",
    "\n",
    "    time_mask = tfio.audio.time_mask(freq_mask, param=10)\n",
    "    time_mask = tf.expand_dims(time_mask, axis=2)\n",
    "    time_mask = tf.repeat(time_mask,repeats=3,axis=2)\n",
    "    return time_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a2ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_labels):\n",
    "    cnn = VGG16(input_shape=[224, 224, 3], weights='imagenet', include_top=False)\n",
    "    \n",
    "    for layer in cnn.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = Flatten()(cnn.output) \n",
    "    output = GaussianNoise(0.1)(x)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(units = num_labels, activation ='softmax')(output)\n",
    "    \n",
    "    model = Model([cnn.input], [output])\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.0005, decay=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2bb68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train, test, num_labels, epoch_amt, save):\n",
    "    if model is None:\n",
    "        model = create_model(num_labels)\n",
    "\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(filepath=\"bestest_model\",\n",
    "                                                 mode='max',\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 save_best_only=True)\n",
    "    \n",
    "    model.fit(train, validation_data=test, epochs=epoch_amt, callbacks=[tensorboard_callback, checkpoint], verbose=True)\n",
    "    \n",
    "    if save:\n",
    "        model.save(\"model\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bcd6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_file(file_name, model, label_encoder):\n",
    "    image = preprocess(file_name)\n",
    "    image = image.numpy().reshape(1, 224, 224, 3)\n",
    "    predicted_label = model.predict([image], verbose=False)\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba1bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(inputPath, label):\n",
    "    spectrogram = preprocess(inputPath)\n",
    "    return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b23ada53",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eac490cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"filename\", \"primary_label\"]\n",
    "df = pd.read_csv(\"./Data/train_metadata.csv\", usecols=cols)\n",
    "#df = df.loc[df['primary_label'] <= \"clcrob\"]\n",
    "saved_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de508e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['file_path'] = df.apply(lambda row: \"./Data/Audio/\" + row.primary_label + \"/\" + row.filename, axis = 1)\n",
    "images = df[\"file_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "273a4f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.pop('primary_label')\n",
    "labels_encoder = LabelEncoder()\n",
    "labels = to_categorical(labels_encoder.fit_transform(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a72a95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95e813c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset = dataset.map(process_images, num_parallel_calls=AUTOTUNE)\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7b5cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = int(len(dataset) * .80)        # 80% of data is for training\n",
    "testing_size = len(dataset) - training_size    # 20% of data is for validating\n",
    "\n",
    "train = dataset.take(training_size)\n",
    "test = dataset.skip(training_size).take(testing_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e9dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"model\")\n",
    "model = train_model(model, train, test, labels.shape[1], 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a6a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_file(\"./Data/Audio/acafly/XC31063.ogg\", model, labels_encoder)\n",
    "classes_x = np.argmax(prediction, axis=1)\n",
    "prediction_class = labels_encoder.inverse_transform(classes_x)\n",
    "str(prediction_class[0]) + \" with \" + str(prediction[0][classes_x][0]*100) + \"% confidence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5276aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ac3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748187c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy on data\n",
    "count = 0\n",
    "correct = 0\n",
    "for index_num, row in saved_df.iterrows():\n",
    "    prediction = predict_file(\"./Data/Audio/\" + row[\"primary_label\"] + \"/\" + row[\"filename\"], model, labels_encoder)\n",
    "    classes_x = np.argmax(prediction, axis=1)\n",
    "    prediction_class = labels_encoder.inverse_transform(classes_x)\n",
    "    if prediction_class[0] == row[\"primary_label\"]:\n",
    "        correct += 1\n",
    "    count += 1\n",
    "    \n",
    "float(correct/count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
