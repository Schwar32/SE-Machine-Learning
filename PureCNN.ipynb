{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13019d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tensorboard import notebook\n",
    "\n",
    "import keras.models\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D, Flatten, Dense, Lambda\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad489fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(file_name):\n",
    "    audio_data, sample_rate = sf.read(file_name)\n",
    "    return audio_data[::4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fda4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    wav = load_audio(file_path)\n",
    "    wav = wav[:120000]\n",
    "    zero_padding = tf.zeros([120000] - tf.shape(wav), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, wav], 0)\n",
    "\n",
    "    spectrogram = tfio.audio.spectrogram(\n",
    "        wav, nfft=1024, window=1024, stride=536)\n",
    "\n",
    "    mel_spectrogram = tfio.audio.melscale(\n",
    "        spectrogram, rate=8000, mels=224, fmin=0, fmax=4000)\n",
    "\n",
    "    dbscale_mel_spectrogram = tfio.audio.dbscale(\n",
    "        mel_spectrogram, top_db=80)\n",
    "\n",
    "    freq_mask = tfio.audio.freq_mask(dbscale_mel_spectrogram, param=5)\n",
    "\n",
    "    time_mask = tfio.audio.time_mask(freq_mask, param=5)\n",
    "    time_mask = tf.expand_dims(time_mask, axis=2)\n",
    "    return time_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a2ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_labels):\n",
    "    vgg = VGG16(input_shape=[224, 224, 3], weights='imagenet', include_top=False)\n",
    "    \n",
    "    for layer in vgg.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Fully connected layers  \n",
    "    x = Flatten()(vgg.output) \n",
    "    output = Dense(units = num_labels, activation ='softmax')(x)\n",
    "    \n",
    "    model = Model([vgg.input], [output])\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2bb68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainAttrX, trainImagesX, trainY, testAttrX, testImagesX, testY, num_labels, batch_amt, epoch_amt, save):\n",
    "    model = create_model(num_labels)\n",
    "\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "    model.fit( x=trainImagesX, y=trainY, validation_data=(testImagesX, testY),\n",
    "        epochs=epoch_amt, batch_size=batch_amt, callbacks=[tensorboard_callback], verbose=False)\n",
    "    \n",
    "    if save:\n",
    "        model.save(\"model\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bcd6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_file(file_name, model, label_encoder, latitude, longitude, date):\n",
    "    image = preprocess(file_name)\n",
    "\n",
    "    data = [[image, latitude, longitude, date]]\n",
    "    df = pd.DataFrame(data, columns=['image', 'latitude', 'longitude', 'date'])\n",
    "    continuous = [\"latitude\", \"longitude\"]\n",
    "    \n",
    "    cs = MinMaxScaler()\n",
    "    predictContinuous = cs.fit_transform(df[continuous])\n",
    "    \n",
    "    predicted_label = model.predict([image.numpy().reshape(1, 157, 64, 1), predictContinuous])\n",
    "    classes_x = np.argmax(predicted_label, axis=1)\n",
    "    prediction_class = labelencoder.inverse_transform(classes_x)\n",
    "    return prediction_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba1bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(df, inputPath):\n",
    "    images = []\n",
    "    for index_num, row in df.iterrows():\n",
    "        images.append(preprocess(inputPath + row[\"primary_label\"] + \"/\" + row[\"filename\"]))\n",
    "    return np.asarray(images).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7dcfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attributes(inputPath):\n",
    "    cols = [\"latitude\", \"longitude\", \"date\", \"time\", \"filename\", \"primary_label\"]\n",
    "    df = pd.read_csv(inputPath, skipinitialspace=True, usecols=cols)\n",
    "    df = df.loc[df['primary_label'] <= \"amecro\"]\n",
    "    df = shuffle(df)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb0e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_attributes(inputPath, train, test):\n",
    "    continuous = [\"latitude\", \"longitude\"]\n",
    "    \n",
    "    cs = MinMaxScaler()\n",
    "    trainContinuous = cs.fit_transform(train[continuous])\n",
    "    testContinuous = cs.transform(test[continuous])\n",
    "    \n",
    "    \n",
    "    dateBinarizer = LabelBinarizer().fit(df[\"date\"])\n",
    "    trainCategorical = dateBinarizer.transform(train[\"date\"])\n",
    "    testCategorical = dateBinarizer.transform(test[\"date\"])\n",
    "    \n",
    "    trainX = trainContinuous\n",
    "    testX = testContinuous\n",
    "    \n",
    "    return (trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac490cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_attributes(\"./Data/train_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a114afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = process_images(df, \"./Data/Audio/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4490111d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(822, 224, 224, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9213dfdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(822, 224, 224, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.repeat(images,repeats=3,axis=3)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd0f6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images / np.max(np.abs(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3832e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(df, images, test_size=0.2, random_state=0)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split\n",
    "label_encoder = LabelEncoder()\n",
    "trainY = to_categorical(label_encoder.fit_transform(trainAttrX[\"primary_label\"]))\n",
    "testY = to_categorical(label_encoder.fit_transform(testAttrX[\"primary_label\"]))\n",
    "\n",
    "(trainAttrX, testAttrX) = process_attributes(df,\n",
    "    trainAttrX, testAttrX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d1f2960",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90f6566b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cea526861dedbbe4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cea526861dedbbe4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8088;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs/fit --host localhost --port 8088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c991be94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 125445    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,840,133\n",
      "Trainable params: 125,445\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_labels = trainY.shape[1]\n",
    "\n",
    "train_model(trainAttrX, trainImagesX, trainY, testAttrX, testImagesX, testY, num_labels, 2, 50, True)\n",
    "\n",
    "#model = keras.models.load_model(\"model\")\n",
    "\n",
    "#preds = model.predict([testImagesX, testAttrX])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3283ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_file(\"./Data/Audio/aldfly/XC477348.ogg\", model, label_encoder,\n",
    "                              42.0458, -79.441, \"2019-05-27\")\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
